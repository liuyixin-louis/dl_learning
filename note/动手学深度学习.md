# 动手学深度学习
## 预备知识
### 数据操作
- 线性代数
另外，PyTorch还支持一些线性函数，这里提一下，免得用起来的时候自己造轮子，具体用法参考官方文档。如下表所示：
函数	功能
trace	对角线元素之和(矩阵的迹)
diag	对角线元素
triu/tril	矩阵的上三角/下三角，可指定偏移量
mm/bmm	矩阵乘法，batch的矩阵乘法
addmm/addbmm/addmv/addr/baddbmm..	矩阵运算
t	转置
dot/cross	内积/外积
inverse	求逆矩阵
svd	奇异值分解


Tensor Operation：https://pytorch.org/docs/stable/tensors.html


- 广播机制
形状不同的tensor在运算时会调整同形状

- 运算内存开销
y = y + x 新内存
y[:] = y + x  y.add_(x)  torch.add(x, y, out=y) inplace

- Tensor和NumPy相互转换

b = a.numpy()
b = torch.from_numpy(a) c = torch.tensor(a)

- tensor on gpu
```
# 以下代码只有在PyTorch GPU版本上才会执行
if torch.cuda.is_available():
    device = torch.device("cuda")          # GPU
    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor
    x = x.to(device)                       # 等价于 .to("cuda")
    z = x + y
    print(z)
    print(z.to("cpu", torch.double))       # to()还可以同时更改数据类型
```

### 梯度
Tensor.
    detach():如果不想要被继续追踪，可以调用.detach()将其从追踪记录中分离出来，这样就可以防止将来的计算被追踪，这样梯度就传不过去了。
    requires_grad:变量需不需要记录梯度信息



