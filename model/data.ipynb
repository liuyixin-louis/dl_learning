{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1HLv8kONEjQQaxOAOi1i9MFAyhinkgogr",
      "authorship_tag": "ABX9TyOgYxi8WztojZAl6n4GEmmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuyixin-louis/dl_learning/blob/master/data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEs4UTG7qI2K",
        "colab_type": "text"
      },
      "source": [
        "# 人民日报+无预训练词嵌入+bilstm(筛后样本估计太小，f1很高，但是实际效果很差)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GywqH7NH_53n",
        "colab_type": "text"
      },
      "source": [
        "Model: \"model_3\"\n",
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "\n",
        "input (InputLayer)           [(None, 97)]              0         \n",
        "_________________________________________________________________\n",
        "layer_embedding (Embedding)  (None, 97, 100)           350000    \n",
        "_________________________________________________________________\n",
        "layer_blstm (Bidirectional)  (None, 97, 256)           235520    \n",
        "_________________________________________________________________\n",
        "layer_dropout (Dropout)      (None, 97, 256)           0         \n",
        "_________________________________________________________________\n",
        "layer_time_distributed (Time (None, 97, 4)             1028      \n",
        "_________________________________________________________________\n",
        "activation_1 (Activation)    (None, 97, 4)             0         "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wWSH1FUqL1A",
        "colab_type": "code",
        "outputId": "20687063-6127-4462-d7a4-3eab2de96a4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install 'kashgari>=1.0.0,<2.0.0'"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kashgari<2.0.0,>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/da/cc2e6d092125c805d0721227f34e288657f6bbb6cd750c491227137053ba/kashgari-1.1.5-py3-none-any.whl (88kB)\n",
            "\r\u001b[K     |███▊                            | 10kB 13.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 30kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 61kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 81kB 3.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 2.8MB/s \n",
            "\u001b[?25hCollecting keras-bert>=0.50.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2c/0f/cdc886c1018943ea62d3209bc964413d5aa9d0eb7e493abd8545be679294/keras-bert-0.81.0.tar.gz\n",
            "Requirement already satisfied: scikit-learn>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (0.22.2.post1)\n",
            "Collecting numpy==1.16.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/2d/e4656149cbadd3a8a0369fcd1a9c7d61cc7b87b3903b85389c70c989a696/numpy-1.16.4-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
            "\u001b[K     |████████████████████████████████| 17.3MB 207kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.23.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (1.0.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (2.10.0)\n",
            "Collecting keras-gpt-2>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/df/19/d11eac066ffcb61ec9edd23c02e4651eaa31f1f67c167a636dd90b6142a4/keras-gpt-2-0.14.0.tar.gz\n",
            "Collecting bert4keras==0.6.5\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/4c/0dfe26eeeb13b46dc1a74f57c7f9531cc0881c5a8efc9f31a058f0c70f61/bert4keras-0.6.5.tar.gz\n",
            "Collecting seqeval==0.0.10\n",
            "  Downloading https://files.pythonhosted.org/packages/55/dd/3bf1c646c310daabae47fceb84ea9ab66df7f518a31a89955290d82b8100/seqeval-0.0.10-py3-none-any.whl\n",
            "Requirement already satisfied: gensim>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from kashgari<2.0.0,>=1.0.0) (3.6.0)\n",
            "Requirement already satisfied: Keras in /usr/local/lib/python3.6/dist-packages (from keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (2.3.1)\n",
            "Collecting keras-transformer>=0.30.0\n",
            "  Downloading https://files.pythonhosted.org/packages/22/b9/9040ec948ef895e71df6bee505a1f7e1c99ffedb409cb6eb329f04ece6e0/keras-transformer-0.33.0.tar.gz\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari<2.0.0,>=1.0.0) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.1->kashgari<2.0.0,>=1.0.0) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari<2.0.0,>=1.0.0) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23.0->kashgari<2.0.0,>=1.0.0) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py->kashgari<2.0.0,>=1.0.0) (1.12.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from keras-gpt-2>=0.8.0->kashgari<2.0.0,>=1.0.0) (2019.12.20)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.11.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras->keras-bert>=0.50.0->kashgari<2.0.0,>=1.0.0) (3.13)\n",
            "Collecting keras-pos-embd>=0.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/09/70/b63ed8fc660da2bb6ae29b9895401c628da5740c048c190b5d7107cadd02/keras-pos-embd-0.11.0.tar.gz\n",
            "Collecting keras-multi-head>=0.22.0\n",
            "  Downloading https://files.pythonhosted.org/packages/40/3e/d0a64bb2ac5217928effe4507c26bbd19b86145d16a1948bc2d4f4c6338a/keras-multi-head-0.22.0.tar.gz\n",
            "Collecting keras-layer-normalization>=0.12.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/0e/d1078df0494bac9ce1a67954e5380b6e7569668f0f3b50a9531c62c1fc4a/keras-layer-normalization-0.14.0.tar.gz\n",
            "Collecting keras-position-wise-feed-forward>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/59/f0faa1037c033059e7e9e7758e6c23b4d1c0772cd48de14c4b6fd4033ad5/keras-position-wise-feed-forward-0.6.0.tar.gz\n",
            "Collecting keras-embed-sim>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bc/20/735fd53f6896e2af63af47e212601c1b8a7a80d00b6126c388c9d1233892/keras-embed-sim-0.7.0.tar.gz\n",
            "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2.49.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2.23.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.12.47)\n",
            "Collecting keras-self-attention==0.41.0\n",
            "  Downloading https://files.pythonhosted.org/packages/1b/1c/01599219bef7266fa43b3316e4f55bcb487734d3bafdc60ffd564f3cfe29/keras-self-attention-0.41.0.tar.gz\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (2020.4.5.1)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.47 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (1.15.47)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (0.9.5)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.47->boto3->smart-open>=1.2.1->gensim>=3.5.0->kashgari<2.0.0,>=1.0.0) (0.15.2)\n",
            "Building wheels for collected packages: keras-bert, keras-gpt-2, bert4keras, keras-transformer, keras-pos-embd, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-self-attention\n",
            "  Building wheel for keras-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-bert: filename=keras_bert-0.81.0-cp36-none-any.whl size=37913 sha256=715b34d69c6943a960a37f7d5693be74c195caa413bc6879c369ad159137be88\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/27/da/ffc2d573aa48b87440ec4f98bc7c992e3a2d899edb2d22ef9e\n",
            "  Building wheel for keras-gpt-2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-gpt-2: filename=keras_gpt_2-0.14.0-cp36-none-any.whl size=10525 sha256=a461c14f3a992d0d6ae63e11826febbbbb0f8fb87efe573faebae3defc8baba1\n",
            "  Stored in directory: /root/.cache/pip/wheels/ec/d8/06/ba8216a77a55b8ba4a5c3932c7df93e87eeaea83ced27822aa\n",
            "  Building wheel for bert4keras (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert4keras: filename=bert4keras-0.6.5-cp36-none-any.whl size=34212 sha256=70c2889023eee6449b3ec9f4f9b7c5bdcadc9e4252193eb4c37b3c324e753a1c\n",
            "  Stored in directory: /root/.cache/pip/wheels/97/82/72/56a894ccb2337a25b679cbac552bf2f15f5e8e798a37313de6\n",
            "  Building wheel for keras-transformer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-transformer: filename=keras_transformer-0.33.0-cp36-none-any.whl size=13260 sha256=d68342183fde27d7753ed0d2740dd2aa6b7832e52fe0c3c296abce572c92fc90\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/98/13/a28402939e1d48edd8704e6b02f223795af4a706815f4bf6d8\n",
            "  Building wheel for keras-pos-embd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-pos-embd: filename=keras_pos_embd-0.11.0-cp36-none-any.whl size=7554 sha256=39c53b8d3e4a118fd1c42e31be2d17639d132da01e6913f70d1a1b094fa7e9d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/a1/a0/ce6b1d49ba1a9a76f592e70cf297b05c96bc9f418146761032\n",
            "  Building wheel for keras-multi-head (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-multi-head: filename=keras_multi_head-0.22.0-cp36-none-any.whl size=15371 sha256=a546a47015132e284994ddaab90a79cad211c1de4d3bd4e7af32ee8f723e042e\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/df/3f/81b36f41b66e6a9cd69224c70a737de2bb6b2f7feb3272c25e\n",
            "  Building wheel for keras-layer-normalization (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-layer-normalization: filename=keras_layer_normalization-0.14.0-cp36-none-any.whl size=5268 sha256=efc7b3ba07313256d8624f77469c3636e9a5e8673b1c2836d22755cb5a13a26a\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/80/22/a638a7d406fd155e507aa33d703e3fa2612b9eb7bb4f4fe667\n",
            "  Building wheel for keras-position-wise-feed-forward (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-position-wise-feed-forward: filename=keras_position_wise_feed_forward-0.6.0-cp36-none-any.whl size=5623 sha256=cfcb8f39bbfeee14adf00915752beaa8df7e0020acad118af0916117aa1d185f\n",
            "  Stored in directory: /root/.cache/pip/wheels/39/e2/e2/3514fef126a00574b13bc0b9e23891800158df3a3c19c96e3b\n",
            "  Building wheel for keras-embed-sim (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-embed-sim: filename=keras_embed_sim-0.7.0-cp36-none-any.whl size=4676 sha256=b778b867cfba51f8aba7818fa549e324aa77baa905dddc04d4bd47abb3c8d037\n",
            "  Stored in directory: /root/.cache/pip/wheels/d1/bc/b1/b0c45cee4ca2e6c86586b0218ffafe7f0703c6d07fdf049866\n",
            "  Building wheel for keras-self-attention (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-self-attention: filename=keras_self_attention-0.41.0-cp36-none-any.whl size=17288 sha256=5f6851106dd53ec15c1dc29bb111a6210910c8fda7d88f9f1a50fdbc91af0154\n",
            "  Stored in directory: /root/.cache/pip/wheels/cc/dc/17/84258b27a04cd38ac91998abe148203720ca696186635db694\n",
            "Successfully built keras-bert keras-gpt-2 bert4keras keras-transformer keras-pos-embd keras-multi-head keras-layer-normalization keras-position-wise-feed-forward keras-embed-sim keras-self-attention\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: numpy, keras-pos-embd, keras-self-attention, keras-multi-head, keras-layer-normalization, keras-position-wise-feed-forward, keras-embed-sim, keras-transformer, keras-bert, keras-gpt-2, bert4keras, seqeval, kashgari\n",
            "  Found existing installation: numpy 1.18.3\n",
            "    Uninstalling numpy-1.18.3:\n",
            "      Successfully uninstalled numpy-1.18.3\n",
            "Successfully installed bert4keras-0.6.5 kashgari-1.1.5 keras-bert-0.81.0 keras-embed-sim-0.7.0 keras-gpt-2-0.14.0 keras-layer-normalization-0.14.0 keras-multi-head-0.22.0 keras-pos-embd-0.11.0 keras-position-wise-feed-forward-0.6.0 keras-self-attention-0.41.0 keras-transformer-0.33.0 numpy-1.16.4 seqeval-0.0.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iB2vHxCSrJ68",
        "colab_type": "code",
        "outputId": "f86a86c2-0f02-4bfe-8351-06c2d7e0665e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHK0kegaqfo8",
        "colab_type": "code",
        "outputId": "47c95d5a-ef07-436f-d401-209f4e99caef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "from kashgari.corpus import ChineseDailyNerCorpus\n",
        "from kashgari.tasks.labeling import BiLSTM_Model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:CUDA GPU available, you can set `kashgari.config.use_cudnn_cell = True` to use CuDNNCell. This will speed up the training, but will make model incompatible with CPU device.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd-CvRTysNSX",
        "colab_type": "code",
        "outputId": "b01e6361-affe-43f4-8a45-944d6010f0bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "import kashgari\n",
        "kashgari.config.use_cudnn_cell = True"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:CuDNN enabled, this will speed up the training, but will make model incompatible with CPU device.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ1VDckqrFQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_x, train_y = ChineseDailyNerCorpus.load_data('train')\n",
        "test_x, test_y = ChineseDailyNerCorpus.load_data('test')\n",
        "valid_x, valid_y = ChineseDailyNerCorpus.load_data('valid')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoFjuqH98g2L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "72749e2c-e584-4a54-dba3-98116773943d"
      },
      "source": [
        "test_y[12][5] == 'I-LOC'"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_6G6L5tsvFS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def only_location(y):\n",
        "  for yi in y:\n",
        "    for i in range(len(yi)):\n",
        "      label =  yi[i]\n",
        "      if label == 'B-LOC' or label == 'I-LOC':\n",
        "        pass\n",
        "      else:\n",
        "        yi[i] = 'O'\n",
        "only_location(test_y)\n",
        "only_location(valid_y)\n",
        "only_location(train_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbZp__9--mCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLG6e6uF95WN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "8bfbe7bd-e565-4431-c4f7-0ca354ace0d2"
      },
      "source": [
        "k = 0\n",
        "for i in train_y:\n",
        "  if 'B-LOC' in i:\n",
        "    k+=1\n",
        "k"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OU27O_plrIhQ",
        "colab_type": "code",
        "outputId": "66f51703-8c5b-4040-bf54-07fee42c4d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BiLSTM_Model()\n",
        "model.fit(train_x, train_y, valid_x, valid_y, epochs=50)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:Sequence length will auto set at 95% of sequence length\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input (InputLayer)           [(None, 97)]              0         \n",
            "_________________________________________________________________\n",
            "layer_embedding (Embedding)  (None, 97, 100)           350000    \n",
            "_________________________________________________________________\n",
            "layer_blstm (Bidirectional)  (None, 97, 256)           235520    \n",
            "_________________________________________________________________\n",
            "layer_dropout (Dropout)      (None, 97, 256)           0         \n",
            "_________________________________________________________________\n",
            "layer_time_distributed (Time (None, 97, 4)             1028      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 97, 4)             0         \n",
            "=================================================================\n",
            "Total params: 586,548\n",
            "Trainable params: 586,548\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9679Epoch 1/50\n",
            "327/327 [==============================] - 20s 60ms/step - loss: 0.1132 - acc: 0.9680 - val_loss: 0.0431 - val_acc: 0.9845\n",
            "Epoch 2/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9872Epoch 1/50\n",
            "327/327 [==============================] - 17s 51ms/step - loss: 0.0358 - acc: 0.9872 - val_loss: 0.0298 - val_acc: 0.9898\n",
            "Epoch 3/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9906Epoch 1/50\n",
            "327/327 [==============================] - 16s 50ms/step - loss: 0.0266 - acc: 0.9906 - val_loss: 0.0257 - val_acc: 0.9918\n",
            "Epoch 4/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9922Epoch 1/50\n",
            "327/327 [==============================] - 16s 49ms/step - loss: 0.0217 - acc: 0.9922 - val_loss: 0.0236 - val_acc: 0.9923\n",
            "Epoch 5/50\n",
            "325/327 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9933Epoch 1/50\n",
            "327/327 [==============================] - 16s 48ms/step - loss: 0.0187 - acc: 0.9933 - val_loss: 0.0225 - val_acc: 0.9924\n",
            "Epoch 6/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9943Epoch 1/50\n",
            "327/327 [==============================] - 16s 48ms/step - loss: 0.0162 - acc: 0.9943 - val_loss: 0.0205 - val_acc: 0.9932\n",
            "Epoch 7/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9950Epoch 1/50\n",
            "327/327 [==============================] - 16s 48ms/step - loss: 0.0142 - acc: 0.9950 - val_loss: 0.0218 - val_acc: 0.9934\n",
            "Epoch 8/50\n",
            "325/327 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9956Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0125 - acc: 0.9956 - val_loss: 0.0200 - val_acc: 0.9940\n",
            "Epoch 9/50\n",
            "325/327 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9962Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0109 - acc: 0.9962 - val_loss: 0.0189 - val_acc: 0.9944\n",
            "Epoch 10/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9967Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 0.0224 - val_acc: 0.9932\n",
            "Epoch 11/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9970Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0087 - acc: 0.9970 - val_loss: 0.0218 - val_acc: 0.9941\n",
            "Epoch 12/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9974Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0075 - acc: 0.9975 - val_loss: 0.0208 - val_acc: 0.9947\n",
            "Epoch 13/50\n",
            "325/327 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9977Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0067 - acc: 0.9977 - val_loss: 0.0213 - val_acc: 0.9942\n",
            "Epoch 14/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9980Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0058 - acc: 0.9980 - val_loss: 0.0241 - val_acc: 0.9942\n",
            "Epoch 15/50\n",
            "325/327 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9982Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0055 - acc: 0.9982 - val_loss: 0.0238 - val_acc: 0.9944\n",
            "Epoch 16/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9985Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0045 - acc: 0.9985 - val_loss: 0.0245 - val_acc: 0.9943\n",
            "Epoch 17/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9987Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0040 - acc: 0.9987 - val_loss: 0.0267 - val_acc: 0.9943\n",
            "Epoch 18/50\n",
            "325/327 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9988Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0035 - acc: 0.9988 - val_loss: 0.0264 - val_acc: 0.9944\n",
            "Epoch 19/50\n",
            "325/327 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9989Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0033 - acc: 0.9989 - val_loss: 0.0280 - val_acc: 0.9941\n",
            "Epoch 20/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9991Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0027 - acc: 0.9991 - val_loss: 0.0288 - val_acc: 0.9943\n",
            "Epoch 21/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0294 - val_acc: 0.9942\n",
            "Epoch 22/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9992Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0024 - acc: 0.9992 - val_loss: 0.0303 - val_acc: 0.9941\n",
            "Epoch 23/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9993Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0023 - acc: 0.9993 - val_loss: 0.0328 - val_acc: 0.9939\n",
            "Epoch 24/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9994Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0017 - acc: 0.9994 - val_loss: 0.0346 - val_acc: 0.9941\n",
            "Epoch 25/50\n",
            "326/327 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9995Epoch 1/50\n",
            "327/327 [==============================] - 15s 47ms/step - loss: 0.0014 - acc: 0.9995 - val_loss: 0.0340 - val_acc: 0.9940\n",
            "Epoch 26/50\n",
            "309/327 [===========================>..] - ETA: 0s - loss: 0.0013 - acc: 0.9996"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-f949a8138784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBiLSTM_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/kashgari/tasks/base_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, x_validate, y_validate, batch_size, epochs, callbacks, fit_kwargs, shuffle)\u001b[0m\n\u001b[1;32m    308\u001b[0m                                                \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                                                \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m                                                **fit_kwargs)\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     def fit_without_generator(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1294\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.6/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZOc_XTKwJ54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def makedata(s):\n",
        "  res = []\n",
        "  for i in s:\n",
        "    res.append(i)\n",
        "  return [res]\n",
        "\n",
        "def visualizeResult(x,y):\n",
        "  for xi,yi in zip(x,y):\n",
        "    for i in range(len(xi)):\n",
        "      if yi[i]!='O':\n",
        "        print (xi[i]+yi[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO4VJGpPwHD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x_data = makedata('疫情通报：。番禺区：小明在确诊病症后，居住于华南理工大学C10学生宿舍，活动于学生第一食堂。')\n",
        "x_data = makedata('小明住在广东省深圳市宝安区西乡街道，确诊之后经常活动于好又多超市')\n",
        "x_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uFzkpOmwCEB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = model.predict(x_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XARu9gOzw2lR",
        "colab_type": "code",
        "outputId": "8c6f6cae-249f-4626-a9e3-c0ae0a8a5067",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "visualizeResult(x_data,y)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "广B-LOC\n",
            "东I-LOC\n",
            "省I-LOC\n",
            "深B-LOC\n",
            "圳I-LOC\n",
            "市I-LOC\n",
            "宝B-LOC\n",
            "安I-LOC\n",
            "区I-LOC\n",
            "西I-LOC\n",
            "乡I-LOC\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1aW2l4wrIfB",
        "colab_type": "text"
      },
      "source": [
        "# CLUENER2020+无预训练词嵌入+bilstm+crf（50epoches,best f1:0.6113左右）\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WPuCLgP9p34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# self.emebdding_size = embedding_size\n",
        "# self.embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "# self.bilstm = nn.LSTM(input_size=embedding_size,hidden_size=hidden_size,\n",
        "#                       batch_first=True,num_layers=2,dropout=drop_p,\n",
        "#                       bidirectional=True)\n",
        "# self.dropout = SpatialDropout(drop_p)\n",
        "# self.layer_norm = LayerNorm(hidden_size * 2)\n",
        "# self.classifier = nn.Linear(hidden_size * 2,len(label2id))\n",
        "# self.crf = CRF(tagset_size=len(label2id), tag_dictionary=label2id, device=device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFkrBFz66wHl",
        "colab_type": "code",
        "outputId": "13d23866-8d72-421a-f3fe-4381a14dfcba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/cluebenchmark/tasks/cluener_public.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-05 07:10:04--  https://storage.googleapis.com/cluebenchmark/tasks/cluener_public.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.119.128, 2607:f8b0:4001:c07::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.119.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1054686 (1.0M) [application/zip]\n",
            "Saving to: ‘cluener_public.zip’\n",
            "\n",
            "\rcluener_public.zip    0%[                    ]       0  --.-KB/s               \rcluener_public.zip  100%[===================>]   1.00M  --.-KB/s    in 0.009s  \n",
            "\n",
            "2020-05-05 07:10:04 (108 MB/s) - ‘cluener_public.zip’ saved [1054686/1054686]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WAaqXviO63CW",
        "colab_type": "code",
        "outputId": "e10cfaab-faf9-40a9-dca7-1af8c663ab2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "! unzip /content/cluener_public.zip -d ./cluener_public/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/cluener_public.zip\n",
            "  inflating: ./cluener_public/train.json  \n",
            "  inflating: ./cluener_public/dev.json  \n",
            "  inflating: ./cluener_public/test.json  \n",
            "  inflating: ./cluener_public/cluener_predict.json  \n",
            "  inflating: ./cluener_public/README.md  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xyVjxoFe7Ed",
        "colab_type": "code",
        "outputId": "6ad591e0-6fe9-4afe-a7a8-2d03b48901e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        }
      },
      "source": [
        "! git clone  https://github.com/CLUEbenchmark/CLUENER2020/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CLUENER2020'...\n",
            "remote: Enumerating objects: 19, done.\u001b[K\n",
            "remote: Counting objects:   5% (1/19)\u001b[K\rremote: Counting objects:  10% (2/19)\u001b[K\rremote: Counting objects:  15% (3/19)\u001b[K\rremote: Counting objects:  21% (4/19)\u001b[K\rremote: Counting objects:  26% (5/19)\u001b[K\rremote: Counting objects:  31% (6/19)\u001b[K\rremote: Counting objects:  36% (7/19)\u001b[K\rremote: Counting objects:  42% (8/19)\u001b[K\rremote: Counting objects:  47% (9/19)\u001b[K\rremote: Counting objects:  52% (10/19)\u001b[K\rremote: Counting objects:  57% (11/19)\u001b[K\rremote: Counting objects:  63% (12/19)\u001b[K\rremote: Counting objects:  68% (13/19)\u001b[K\rremote: Counting objects:  73% (14/19)\u001b[K\rremote: Counting objects:  78% (15/19)\u001b[K\rremote: Counting objects:  84% (16/19)\u001b[K\rremote: Counting objects:  89% (17/19)\u001b[K\rremote: Counting objects:  94% (18/19)\u001b[K\rremote: Counting objects: 100% (19/19)\u001b[K\rremote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects:   6% (1/15)\u001b[K\rremote: Compressing objects:  13% (2/15)\u001b[K\rremote: Compressing objects:  20% (3/15)\u001b[K\rremote: Compressing objects:  26% (4/15)\u001b[K\rremote: Compressing objects:  33% (5/15)\u001b[K\rremote: Compressing objects:  40% (6/15)\u001b[K\rremote: Compressing objects:  46% (7/15)\u001b[K\rremote: Compressing objects:  53% (8/15)\u001b[K\rremote: Compressing objects:  60% (9/15)\u001b[K\rremote: Compressing objects:  66% (10/15)\u001b[K\rremote: Compressing objects:  73% (11/15)\u001b[K\rremote: Compressing objects:  80% (12/15)\u001b[K\rremote: Compressing objects:  86% (13/15)\u001b[K\rremote: Compressing objects:  93% (14/15)\u001b[K\rremote: Compressing objects: 100% (15/15)\u001b[K\rremote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "Receiving objects:   0% (1/352)   \rReceiving objects:   1% (4/352)   \rReceiving objects:   2% (8/352)   \rReceiving objects:   3% (11/352)   \rReceiving objects:   4% (15/352)   \rReceiving objects:   5% (18/352)   \rReceiving objects:   6% (22/352)   \rReceiving objects:   7% (25/352)   \rReceiving objects:   8% (29/352)   \rReceiving objects:   9% (32/352)   \rReceiving objects:  10% (36/352)   \rReceiving objects:  11% (39/352)   \rReceiving objects:  12% (43/352)   \rReceiving objects:  13% (46/352)   \rReceiving objects:  14% (50/352)   \rReceiving objects:  15% (53/352)   \rReceiving objects:  16% (57/352)   \rReceiving objects:  17% (60/352)   \rReceiving objects:  18% (64/352)   \rReceiving objects:  19% (67/352)   \rReceiving objects:  20% (71/352)   \rReceiving objects:  21% (74/352)   \rReceiving objects:  22% (78/352)   \rReceiving objects:  23% (81/352)   \rReceiving objects:  24% (85/352)   \rReceiving objects:  25% (88/352)   \rReceiving objects:  26% (92/352)   \rReceiving objects:  27% (96/352)   \rReceiving objects:  28% (99/352)   \rReceiving objects:  29% (103/352)   \rReceiving objects:  30% (106/352)   \rReceiving objects:  31% (110/352)   \rReceiving objects:  32% (113/352)   \rReceiving objects:  33% (117/352)   \rReceiving objects:  34% (120/352)   \rReceiving objects:  35% (124/352)   \rReceiving objects:  36% (127/352)   \rReceiving objects:  37% (131/352)   \rReceiving objects:  38% (134/352)   \rReceiving objects:  39% (138/352)   \rReceiving objects:  40% (141/352)   \rReceiving objects:  41% (145/352)   \rReceiving objects:  42% (148/352)   \rReceiving objects:  43% (152/352)   \rReceiving objects:  44% (155/352)   \rReceiving objects:  45% (159/352)   \rReceiving objects:  46% (162/352)   \rReceiving objects:  47% (166/352)   \rReceiving objects:  48% (169/352)   \rReceiving objects:  49% (173/352)   \rReceiving objects:  50% (176/352)   \rReceiving objects:  51% (180/352)   \rReceiving objects:  52% (184/352)   \rReceiving objects:  53% (187/352)   \rReceiving objects:  54% (191/352)   \rReceiving objects:  55% (194/352)   \rReceiving objects:  56% (198/352)   \rReceiving objects:  57% (201/352)   \rReceiving objects:  58% (205/352)   \rReceiving objects:  59% (208/352)   \rReceiving objects:  60% (212/352)   \rReceiving objects:  61% (215/352)   \rReceiving objects:  62% (219/352)   \rReceiving objects:  63% (222/352)   \rReceiving objects:  64% (226/352)   \rremote: Total 352 (delta 0), reused 15 (delta 0), pack-reused 333\u001b[K\n",
            "Receiving objects:  65% (229/352)   \rReceiving objects:  66% (233/352)   \rReceiving objects:  67% (236/352)   \rReceiving objects:  68% (240/352)   \rReceiving objects:  69% (243/352)   \rReceiving objects:  70% (247/352)   \rReceiving objects:  71% (250/352)   \rReceiving objects:  72% (254/352)   \rReceiving objects:  73% (257/352)   \rReceiving objects:  74% (261/352)   \rReceiving objects:  75% (264/352)   \rReceiving objects:  76% (268/352)   \rReceiving objects:  77% (272/352)   \rReceiving objects:  78% (275/352)   \rReceiving objects:  79% (279/352)   \rReceiving objects:  80% (282/352)   \rReceiving objects:  81% (286/352)   \rReceiving objects:  82% (289/352)   \rReceiving objects:  83% (293/352)   \rReceiving objects:  84% (296/352)   \rReceiving objects:  85% (300/352)   \rReceiving objects:  86% (303/352)   \rReceiving objects:  87% (307/352)   \rReceiving objects:  88% (310/352)   \rReceiving objects:  89% (314/352)   \rReceiving objects:  90% (317/352)   \rReceiving objects:  91% (321/352)   \rReceiving objects:  92% (324/352)   \rReceiving objects:  93% (328/352)   \rReceiving objects:  94% (331/352)   \rReceiving objects:  95% (335/352)   \rReceiving objects:  96% (338/352)   \rReceiving objects:  97% (342/352)   \rReceiving objects:  98% (345/352)   \rReceiving objects:  99% (349/352)   \rReceiving objects: 100% (352/352)   \rReceiving objects: 100% (352/352), 890.81 KiB | 6.70 MiB/s, done.\n",
            "Resolving deltas:   0% (0/162)   \rResolving deltas:  17% (28/162)   \rResolving deltas:  18% (30/162)   \rResolving deltas:  19% (31/162)   \rResolving deltas:  20% (33/162)   \rResolving deltas:  23% (38/162)   \rResolving deltas:  24% (40/162)   \rResolving deltas:  25% (41/162)   \rResolving deltas:  27% (44/162)   \rResolving deltas:  28% (46/162)   \rResolving deltas:  30% (49/162)   \rResolving deltas:  32% (52/162)   \rResolving deltas:  33% (55/162)   \rResolving deltas:  35% (57/162)   \rResolving deltas:  39% (64/162)   \rResolving deltas:  40% (65/162)   \rResolving deltas:  41% (67/162)   \rResolving deltas:  43% (70/162)   \rResolving deltas:  45% (73/162)   \rResolving deltas:  47% (77/162)   \rResolving deltas:  51% (84/162)   \rResolving deltas:  53% (87/162)   \rResolving deltas:  54% (88/162)   \rResolving deltas:  61% (100/162)   \rResolving deltas:  62% (102/162)   \rResolving deltas:  64% (104/162)   \rResolving deltas:  65% (106/162)   \rResolving deltas:  66% (107/162)   \rResolving deltas:  67% (109/162)   \rResolving deltas:  68% (111/162)   \rResolving deltas:  69% (113/162)   \rResolving deltas:  77% (126/162)   \rResolving deltas:  78% (127/162)   \rResolving deltas:  83% (136/162)   \rResolving deltas:  85% (139/162)   \rResolving deltas:  86% (140/162)   \rResolving deltas:  87% (141/162)   \rResolving deltas:  88% (144/162)   \rResolving deltas:  90% (146/162)   \rResolving deltas: 100% (162/162)   \rResolving deltas: 100% (162/162), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGO0SRop5sCT",
        "colab_type": "code",
        "outputId": "ed559104-85f9-4f42-ee29-a5a57fe0a2c4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "!pip install jsonlines"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y2v69qW2d7_X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        " \n",
        "# print(os.getcwd())\n",
        " \n",
        " \n",
        "# 修改工作路径\n",
        "# import os\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        " \n",
        "path = \"/content/CLUENER2020/bilstm_crf_pytorch\"\n",
        "os.chdir(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ej4GeAqfLiK",
        "colab_type": "code",
        "outputId": "3992963c-9543-40ab-eca3-d6c3950d126f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python download_clue_data.py --data_dir=./dataset --tasks=cluener"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading and extracting cluener...\n",
            "\tCompleted! Downloaded cluener data to directory ./dataset/cluener\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LLa-s02fU6b",
        "colab_type": "code",
        "outputId": "ac7210ff-eb1e-424b-d7ef-d65a0f01c6c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python run_lstm_crf.py --do_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/05/2020 07:15:49 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-train_bilstm_crf_ner\n",
            "66 batches created\n",
            "Epoch 1/50\n",
            "[Training] 66/66 [==============================] 192.7ms/step  loss: 3.4617  \n",
            "05/05/2020 07:16:02 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 763.1ms/step \n",
            "05/05/2020 07:16:09 - INFO - root -   \n",
            "Epoch: 1 -  loss: 15.1076 - eval_loss: 11.3870 - eval_acc: 0.3220 - eval_recall: 0.3056 - eval_f1: 0.3136 \n",
            "05/05/2020 07:16:09 - INFO - root -   \n",
            "Epoch 1: eval_f1 improved from 0 to 0.3136176066024759\n",
            "05/05/2020 07:16:09 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:16:09 - INFO - root -   Subject: address - Acc: 0.322 - Recall: 0.3056 - F1: 0.3136\n",
            "Epoch 2/50\n",
            "[Training] 66/66 [==============================] 198.2ms/step  loss: 1.8282  \n",
            "05/05/2020 07:16:22 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 754.7ms/step \n",
            "05/05/2020 07:16:29 - INFO - root -   \n",
            "Epoch: 2 -  loss: 8.6197 - eval_loss: 8.6573 - eval_acc: 0.3985 - eval_recall: 0.4209 - eval_f1: 0.4094 \n",
            "05/05/2020 07:16:29 - INFO - root -   \n",
            "Epoch 2: eval_f1 improved from 0.3136176066024759 to 0.409387222946545\n",
            "05/05/2020 07:16:29 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:16:29 - INFO - root -   Subject: address - Acc: 0.3985 - Recall: 0.4209 - F1: 0.4094\n",
            "Epoch 3/50\n",
            "[Training] 66/66 [==============================] 193.5ms/step  loss: 1.0669  \n",
            "05/05/2020 07:16:41 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 768.1ms/step \n",
            "05/05/2020 07:16:48 - INFO - root -   \n",
            "Epoch: 3 -  loss: 6.2705 - eval_loss: 8.8128 - eval_acc: 0.3858 - eval_recall: 0.5255 - eval_f1: 0.4449 \n",
            "05/05/2020 07:16:48 - INFO - root -   \n",
            "Epoch 3: eval_f1 improved from 0.409387222946545 to 0.4449489216799092\n",
            "05/05/2020 07:16:48 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:16:48 - INFO - root -   Subject: address - Acc: 0.3858 - Recall: 0.5255 - F1: 0.4449\n",
            "Epoch 4/50\n",
            "[Training] 66/66 [==============================] 196.4ms/step  loss: 0.6528  \n",
            "05/05/2020 07:17:01 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 767.1ms/step \n",
            "05/05/2020 07:17:08 - INFO - root -   \n",
            "Epoch: 4 -  loss: 5.1115 - eval_loss: 9.5615 - eval_acc: 0.3850 - eval_recall: 0.5523 - eval_f1: 0.4537 \n",
            "05/05/2020 07:17:08 - INFO - root -   \n",
            "Epoch 4: eval_f1 improved from 0.4449489216799092 to 0.4537444933920705\n",
            "05/05/2020 07:17:08 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:17:08 - INFO - root -   Subject: address - Acc: 0.385 - Recall: 0.5523 - F1: 0.4537\n",
            "Epoch 5/50\n",
            "[Training] 66/66 [==============================] 195.5ms/step  loss: 0.3756  \n",
            "05/05/2020 07:17:21 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 756.6ms/step \n",
            "05/05/2020 07:17:28 - INFO - root -   \n",
            "Epoch: 5 -  loss: 4.4150 - eval_loss: 8.3538 - eval_acc: 0.4872 - eval_recall: 0.5121 - eval_f1: 0.4993 \n",
            "05/05/2020 07:17:28 - INFO - root -   \n",
            "Epoch 5: eval_f1 improved from 0.4537444933920705 to 0.4993464052287582\n",
            "05/05/2020 07:17:28 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:17:28 - INFO - root -   Subject: address - Acc: 0.4872 - Recall: 0.5121 - F1: 0.4993\n",
            "Epoch 6/50\n",
            "[Training] 66/66 [==============================] 196.0ms/step  loss: 0.1045  \n",
            "05/05/2020 07:17:41 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 761.0ms/step \n",
            "05/05/2020 07:17:48 - INFO - root -   \n",
            "Epoch: 6 -  loss: 3.2648 - eval_loss: 9.3199 - eval_acc: 0.4344 - eval_recall: 0.4879 - eval_f1: 0.4596 \n",
            "Epoch 7/50\n",
            "[Training] 66/66 [==============================] 195.9ms/step  loss: 0.3649  \n",
            "05/05/2020 07:18:01 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 756.1ms/step \n",
            "05/05/2020 07:18:08 - INFO - root -   \n",
            "Epoch: 7 -  loss: 2.8273 - eval_loss: 8.5844 - eval_acc: 0.5782 - eval_recall: 0.4558 - eval_f1: 0.5097 \n",
            "05/05/2020 07:18:08 - INFO - root -   \n",
            "Epoch 7: eval_f1 improved from 0.4993464052287582 to 0.5097451274362818\n",
            "05/05/2020 07:18:08 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:18:08 - INFO - root -   Subject: address - Acc: 0.5782 - Recall: 0.4558 - F1: 0.5097\n",
            "Epoch 8/50\n",
            "[Training] 66/66 [==============================] 195.5ms/step  loss: 0.1880  \n",
            "05/05/2020 07:18:20 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 750.8ms/step \n",
            "05/05/2020 07:18:27 - INFO - root -   \n",
            "Epoch: 8 -  loss: 2.1197 - eval_loss: 9.0099 - eval_acc: 0.5460 - eval_recall: 0.4772 - eval_f1: 0.5093 \n",
            "Epoch 9/50\n",
            "[Training] 66/66 [==============================] 196.2ms/step  loss: 0.0697  \n",
            "05/05/2020 07:18:40 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 760.6ms/step \n",
            "05/05/2020 07:18:47 - INFO - root -   \n",
            "Epoch: 9 -  loss: 1.6860 - eval_loss: 11.5515 - eval_acc: 0.5430 - eval_recall: 0.4906 - eval_f1: 0.5155 \n",
            "05/05/2020 07:18:47 - INFO - root -   \n",
            "Epoch 9: eval_f1 improved from 0.5097451274362818 to 0.5154929577464787\n",
            "05/05/2020 07:18:47 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:18:47 - INFO - root -   Subject: address - Acc: 0.543 - Recall: 0.4906 - F1: 0.5155\n",
            "Epoch 10/50\n",
            "[Training] 66/66 [==============================] 196.1ms/step  loss: 0.0402  \n",
            "05/05/2020 07:19:00 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 758.4ms/step \n",
            "05/05/2020 07:19:07 - INFO - root -   \n",
            "Epoch: 10 -  loss: 1.2943 - eval_loss: 12.7364 - eval_acc: 0.5312 - eval_recall: 0.5469 - eval_f1: 0.5390 \n",
            "05/05/2020 07:19:07 - INFO - root -   \n",
            "Epoch 10: eval_f1 improved from 0.5154929577464787 to 0.5389696169088508\n",
            "05/05/2020 07:19:07 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:19:07 - INFO - root -   Subject: address - Acc: 0.5312 - Recall: 0.5469 - F1: 0.539\n",
            "Epoch 11/50\n",
            "[Training] 66/66 [==============================] 195.1ms/step  loss: 0.0052  \n",
            "05/05/2020 07:19:20 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 755.5ms/step \n",
            "05/05/2020 07:19:27 - INFO - root -   \n",
            "Epoch: 11 -  loss: 0.9993 - eval_loss: 13.3469 - eval_acc: 0.4728 - eval_recall: 0.5818 - eval_f1: 0.5216 \n",
            "Epoch 12/50\n",
            "[Training] 66/66 [==============================] 196.4ms/step  loss: 0.0100  \n",
            "05/05/2020 07:19:40 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 751.4ms/step \n",
            "05/05/2020 07:19:46 - INFO - root -   \n",
            "Epoch: 12 -  loss: 0.9211 - eval_loss: 14.0369 - eval_acc: 0.5111 - eval_recall: 0.5550 - eval_f1: 0.5321 \n",
            "Epoch 13/50\n",
            "[Training] 66/66 [==============================] 196.4ms/step  loss: 0.0155  \n",
            "05/05/2020 07:19:59 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 751.5ms/step \n",
            "05/05/2020 07:20:06 - INFO - root -   \n",
            "Epoch: 13 -  loss: 0.8318 - eval_loss: 11.5347 - eval_acc: 0.5246 - eval_recall: 0.6005 - eval_f1: 0.5600 \n",
            "05/05/2020 07:20:06 - INFO - root -   \n",
            "Epoch 13: eval_f1 improved from 0.5389696169088508 to 0.5599999999999999\n",
            "05/05/2020 07:20:06 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:20:06 - INFO - root -   Subject: address - Acc: 0.5246 - Recall: 0.6005 - F1: 0.56\n",
            "Epoch 14/50\n",
            "[Training] 66/66 [==============================] 195.6ms/step  loss: 0.0042  \n",
            "05/05/2020 07:20:19 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 755.2ms/step \n",
            "05/05/2020 07:20:26 - INFO - root -   \n",
            "Epoch: 14 -  loss: 0.5446 - eval_loss: 11.4069 - eval_acc: 0.5656 - eval_recall: 0.5550 - eval_f1: 0.5602 \n",
            "05/05/2020 07:20:26 - INFO - root -   \n",
            "Epoch 14: eval_f1 improved from 0.5599999999999999 to 0.5602165087956699\n",
            "05/05/2020 07:20:26 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:20:26 - INFO - root -   Subject: address - Acc: 0.5656 - Recall: 0.555 - F1: 0.5602\n",
            "Epoch 15/50\n",
            "[Training] 66/66 [==============================] 195.8ms/step  loss: 0.0071  \n",
            "05/05/2020 07:20:39 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 752.3ms/step \n",
            "05/05/2020 07:20:46 - INFO - root -   \n",
            "Epoch: 15 -  loss: 0.4564 - eval_loss: 12.8096 - eval_acc: 0.4908 - eval_recall: 0.5737 - eval_f1: 0.5290 \n",
            "Epoch 16/50\n",
            "[Training] 66/66 [==============================] 197.6ms/step  loss: 0.1598  \n",
            "05/05/2020 07:20:59 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 752.5ms/step \n",
            "05/05/2020 07:21:05 - INFO - root -   \n",
            "Epoch: 16 -  loss: 0.4766 - eval_loss: 11.6579 - eval_acc: 0.5506 - eval_recall: 0.5979 - eval_f1: 0.5733 \n",
            "05/05/2020 07:21:05 - INFO - root -   \n",
            "Epoch 16: eval_f1 improved from 0.5602165087956699 to 0.5732647814910025\n",
            "05/05/2020 07:21:05 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:21:05 - INFO - root -   Subject: address - Acc: 0.5506 - Recall: 0.5979 - F1: 0.5733\n",
            "Epoch 17/50\n",
            "[Training] 66/66 [==============================] 194.1ms/step  loss: 0.0050  \n",
            "05/05/2020 07:21:18 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 761.5ms/step \n",
            "05/05/2020 07:21:25 - INFO - root -   \n",
            "Epoch: 17 -  loss: 0.3125 - eval_loss: 11.5598 - eval_acc: 0.5478 - eval_recall: 0.5684 - eval_f1: 0.5579 \n",
            "Epoch 18/50\n",
            "[Training] 66/66 [==============================] 194.6ms/step  loss: 0.0063  \n",
            "05/05/2020 07:21:38 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 745.7ms/step \n",
            "05/05/2020 07:21:45 - INFO - root -   \n",
            "Epoch: 18 -  loss: 0.3122 - eval_loss: 12.7008 - eval_acc: 0.5982 - eval_recall: 0.5469 - eval_f1: 0.5714 \n",
            "Epoch 19/50\n",
            "[Training] 66/66 [==============================] 192.5ms/step  loss: 0.0038  \n",
            "05/05/2020 07:21:57 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 745.0ms/step \n",
            "05/05/2020 07:22:04 - INFO - root -   \n",
            "Epoch: 19 -  loss: 0.3220 - eval_loss: 12.4556 - eval_acc: 0.5761 - eval_recall: 0.6086 - eval_f1: 0.5919 \n",
            "05/05/2020 07:22:04 - INFO - root -   \n",
            "Epoch 19: eval_f1 improved from 0.5732647814910025 to 0.5919165580182529\n",
            "05/05/2020 07:22:04 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:22:04 - INFO - root -   Subject: address - Acc: 0.5761 - Recall: 0.6086 - F1: 0.5919\n",
            "Epoch 20/50\n",
            "[Training] 66/66 [==============================] 198.0ms/step  loss: 0.0013  \n",
            "05/05/2020 07:22:17 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 754.8ms/step \n",
            "05/05/2020 07:22:24 - INFO - root -   \n",
            "Epoch: 20 -  loss: 0.1740 - eval_loss: 14.9798 - eval_acc: 0.5279 - eval_recall: 0.6086 - eval_f1: 0.5654 \n",
            "Epoch 21/50\n",
            "[Training] 66/66 [==============================] 194.8ms/step  loss: 0.0024  \n",
            "05/05/2020 07:22:37 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 755.2ms/step \n",
            "05/05/2020 07:22:44 - INFO - root -   \n",
            "Epoch: 21 -  loss: 0.1895 - eval_loss: 12.1041 - eval_acc: 0.5690 - eval_recall: 0.6193 - eval_f1: 0.5931 \n",
            "05/05/2020 07:22:44 - INFO - root -   \n",
            "Epoch 21: eval_f1 improved from 0.5919165580182529 to 0.5930680359435173\n",
            "05/05/2020 07:22:44 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:22:44 - INFO - root -   Subject: address - Acc: 0.569 - Recall: 0.6193 - F1: 0.5931\n",
            "Epoch 22/50\n",
            "[Training] 66/66 [==============================] 196.4ms/step  loss: 0.0027  \n",
            "05/05/2020 07:22:57 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 765.2ms/step \n",
            "05/05/2020 07:23:04 - INFO - root -   \n",
            "Epoch: 22 -  loss: 0.1990 - eval_loss: 12.9937 - eval_acc: 0.5706 - eval_recall: 0.5523 - eval_f1: 0.5613 \n",
            "Epoch 23/50\n",
            "[Training] 66/66 [==============================] 194.8ms/step  loss: 0.0005  \n",
            "05/05/2020 07:23:17 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 747.9ms/step \n",
            "05/05/2020 07:23:23 - INFO - root -   \n",
            "Epoch: 23 -  loss: 0.1908 - eval_loss: 13.8405 - eval_acc: 0.5714 - eval_recall: 0.5469 - eval_f1: 0.5589 \n",
            "Epoch 24/50\n",
            "[Training] 66/66 [==============================] 195.3ms/step  loss: 0.0021  \n",
            "05/05/2020 07:23:36 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 743.7ms/step \n",
            "05/05/2020 07:23:43 - INFO - root -   \n",
            "Epoch: 24 -  loss: 0.1921 - eval_loss: 13.6432 - eval_acc: 0.6108 - eval_recall: 0.5469 - eval_f1: 0.5771 \n",
            "Epoch 25/50\n",
            "[Training] 66/66 [==============================] 195.0ms/step  loss: 0.0077  \n",
            "05/05/2020 07:23:56 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 754.4ms/step \n",
            "05/05/2020 07:24:03 - INFO - root -   \n",
            "Epoch: 25 -  loss: 0.1877 - eval_loss: 14.0378 - eval_acc: 0.6172 - eval_recall: 0.5013 - eval_f1: 0.5533 \n",
            "\n",
            "Epoch 00025: reducing learning rate to 0.0005.\n",
            "Epoch 26/50\n",
            "[Training] 66/66 [==============================] 197.3ms/step  loss: 0.0017  \n",
            "05/05/2020 07:24:16 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 770.3ms/step \n",
            "05/05/2020 07:24:23 - INFO - root -   \n",
            "Epoch: 26 -  loss: 0.1602 - eval_loss: 12.0169 - eval_acc: 0.6099 - eval_recall: 0.5282 - eval_f1: 0.5661 \n",
            "Epoch 27/50\n",
            "[Training] 66/66 [==============================] 196.1ms/step  loss: 0.0016  \n",
            "05/05/2020 07:24:35 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 760.3ms/step \n",
            "05/05/2020 07:24:42 - INFO - root -   \n",
            "Epoch: 27 -  loss: 0.0302 - eval_loss: 12.5661 - eval_acc: 0.6047 - eval_recall: 0.5576 - eval_f1: 0.5802 \n",
            "Epoch 28/50\n",
            "[Training] 66/66 [==============================] 199.1ms/step  loss: 0.0005  \n",
            "05/05/2020 07:24:55 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 753.6ms/step \n",
            "05/05/2020 07:25:02 - INFO - root -   \n",
            "Epoch: 28 -  loss: 0.0162 - eval_loss: 12.7888 - eval_acc: 0.6264 - eval_recall: 0.5845 - eval_f1: 0.6047 \n",
            "05/05/2020 07:25:02 - INFO - root -   \n",
            "Epoch 28: eval_f1 improved from 0.5930680359435173 to 0.6047156726768377\n",
            "05/05/2020 07:25:02 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:25:02 - INFO - root -   Subject: address - Acc: 0.6264 - Recall: 0.5845 - F1: 0.6047\n",
            "Epoch 29/50\n",
            "[Training] 66/66 [==============================] 196.6ms/step  loss: 0.0007  \n",
            "05/05/2020 07:25:15 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 757.3ms/step \n",
            "05/05/2020 07:25:22 - INFO - root -   \n",
            "Epoch: 29 -  loss: 0.0097 - eval_loss: 13.4009 - eval_acc: 0.6217 - eval_recall: 0.5684 - eval_f1: 0.5938 \n",
            "Epoch 30/50\n",
            "[Training] 66/66 [==============================] 196.6ms/step  loss: 0.0005  \n",
            "05/05/2020 07:25:35 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 763.0ms/step \n",
            "05/05/2020 07:25:42 - INFO - root -   \n",
            "Epoch: 30 -  loss: 0.0132 - eval_loss: 13.9115 - eval_acc: 0.6383 - eval_recall: 0.5630 - eval_f1: 0.5983 \n",
            "Epoch 31/50\n",
            "[Training] 66/66 [==============================] 196.6ms/step  loss: 0.0002  \n",
            "05/05/2020 07:25:55 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 753.6ms/step \n",
            "05/05/2020 07:26:02 - INFO - root -   \n",
            "Epoch: 31 -  loss: 0.0063 - eval_loss: 14.2336 - eval_acc: 0.6450 - eval_recall: 0.5845 - eval_f1: 0.6132 \n",
            "05/05/2020 07:26:02 - INFO - root -   \n",
            "Epoch 31: eval_f1 improved from 0.6047156726768377 to 0.6132208157524612\n",
            "05/05/2020 07:26:02 - INFO - root -   save model to disk.\n",
            "Eval Entity Score: \n",
            "05/05/2020 07:26:02 - INFO - root -   Subject: address - Acc: 0.645 - Recall: 0.5845 - F1: 0.6132\n",
            "Epoch 32/50\n",
            "[Training] 66/66 [==============================] 196.4ms/step  loss: 0.0003  \n",
            "05/05/2020 07:26:15 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 748.7ms/step \n",
            "05/05/2020 07:26:22 - INFO - root -   \n",
            "Epoch: 32 -  loss: 0.0058 - eval_loss: 14.8892 - eval_acc: 0.6310 - eval_recall: 0.5684 - eval_f1: 0.5980 \n",
            "Epoch 33/50\n",
            "[Training] 66/66 [==============================] 196.8ms/step  loss: 0.0043  \n",
            "05/05/2020 07:26:35 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 772.3ms/step \n",
            "05/05/2020 07:26:41 - INFO - root -   \n",
            "Epoch: 33 -  loss: 0.0124 - eval_loss: 14.5427 - eval_acc: 0.6276 - eval_recall: 0.5737 - eval_f1: 0.5994 \n",
            "Epoch 34/50\n",
            "[Training] 66/66 [==============================] 196.0ms/step  loss: 0.0004  \n",
            "05/05/2020 07:26:54 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 751.9ms/step \n",
            "05/05/2020 07:27:01 - INFO - root -   \n",
            "Epoch: 34 -  loss: 0.0050 - eval_loss: 14.5538 - eval_acc: 0.6272 - eval_recall: 0.5684 - eval_f1: 0.5963 \n",
            "Epoch 35/50\n",
            "[Training] 66/66 [==============================] 193.4ms/step  loss: 0.0002  \n",
            "05/05/2020 07:27:14 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 762.1ms/step \n",
            "05/05/2020 07:27:21 - INFO - root -   \n",
            "Epoch: 35 -  loss: 0.0029 - eval_loss: 14.8193 - eval_acc: 0.6228 - eval_recall: 0.5576 - eval_f1: 0.5884 \n",
            "\n",
            "Epoch 00035: reducing learning rate to 0.00025.\n",
            "Epoch 36/50\n",
            "[Training] 66/66 [==============================] 195.4ms/step  loss: 0.0030  \n",
            "05/05/2020 07:27:34 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 759.6ms/step \n",
            "05/05/2020 07:27:41 - INFO - root -   \n",
            "Epoch: 36 -  loss: 0.0035 - eval_loss: 15.1139 - eval_acc: 0.6341 - eval_recall: 0.5576 - eval_f1: 0.5934 \n",
            "Epoch 37/50\n",
            "[Training] 66/66 [==============================] 197.5ms/step  loss: 0.0002  \n",
            "05/05/2020 07:27:54 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 757.9ms/step \n",
            "05/05/2020 07:28:00 - INFO - root -   \n",
            "Epoch: 37 -  loss: 0.0048 - eval_loss: 14.9661 - eval_acc: 0.6272 - eval_recall: 0.5818 - eval_f1: 0.6036 \n",
            "Epoch 38/50\n",
            "[Training] 66/66 [==============================] 195.7ms/step  loss: 0.0001  \n",
            "05/05/2020 07:28:13 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 752.7ms/step \n",
            "05/05/2020 07:28:20 - INFO - root -   \n",
            "Epoch: 38 -  loss: 0.0042 - eval_loss: 15.2549 - eval_acc: 0.6331 - eval_recall: 0.5737 - eval_f1: 0.6020 \n",
            "\n",
            "Epoch 00038: reducing learning rate to 0.000125.\n",
            "Epoch 39/50\n",
            "[Training] 66/66 [==============================] 196.3ms/step  loss: 0.0002  \n",
            "05/05/2020 07:28:33 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 765.1ms/step \n",
            "05/05/2020 07:28:40 - INFO - root -   \n",
            "Epoch: 39 -  loss: 0.0024 - eval_loss: 15.2787 - eval_acc: 0.6294 - eval_recall: 0.5737 - eval_f1: 0.6003 \n",
            "Epoch 40/50\n",
            "[Training] 66/66 [==============================] 194.8ms/step  loss: 0.0000  \n",
            "05/05/2020 07:28:53 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 761.8ms/step \n",
            "05/05/2020 07:29:00 - INFO - root -   \n",
            "Epoch: 40 -  loss: 0.0029 - eval_loss: 15.2976 - eval_acc: 0.6302 - eval_recall: 0.5710 - eval_f1: 0.5992 \n",
            "Epoch 41/50\n",
            "[Training] 66/66 [==============================] 195.8ms/step  loss: 0.0004  \n",
            "05/05/2020 07:29:13 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 756.4ms/step \n",
            "05/05/2020 07:29:20 - INFO - root -   \n",
            "Epoch: 41 -  loss: 0.0031 - eval_loss: 15.3493 - eval_acc: 0.6437 - eval_recall: 0.5764 - eval_f1: 0.6082 \n",
            "\n",
            "Epoch 00041: reducing learning rate to 6.25e-05.\n",
            "Epoch 42/50\n",
            "[Training] 66/66 [==============================] 195.5ms/step  loss: 0.0000  \n",
            "05/05/2020 07:29:32 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 758.3ms/step \n",
            "05/05/2020 07:29:39 - INFO - root -   \n",
            "Epoch: 42 -  loss: 0.0028 - eval_loss: 15.3489 - eval_acc: 0.6380 - eval_recall: 0.5764 - eval_f1: 0.6056 \n",
            "Epoch 43/50\n",
            "[Training] 66/66 [==============================] 195.7ms/step  loss: 0.0002  \n",
            "05/05/2020 07:29:52 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 764.9ms/step \n",
            "05/05/2020 07:29:59 - INFO - root -   \n",
            "Epoch: 43 -  loss: 0.0035 - eval_loss: 15.3319 - eval_acc: 0.6393 - eval_recall: 0.5845 - eval_f1: 0.6106 \n",
            "Epoch 44/50\n",
            "[Training] 66/66 [==============================] 196.3ms/step  loss: 0.0001  \n",
            "05/05/2020 07:30:12 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 755.3ms/step \n",
            "05/05/2020 07:30:19 - INFO - root -   \n",
            "Epoch: 44 -  loss: 0.0035 - eval_loss: 15.2921 - eval_acc: 0.6319 - eval_recall: 0.5845 - eval_f1: 0.6072 \n",
            "\n",
            "Epoch 00044: reducing learning rate to 3.125e-05.\n",
            "Epoch 45/50\n",
            "[Training] 66/66 [==============================] 196.2ms/step  loss: 0.0001  \n",
            "05/05/2020 07:30:32 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 757.3ms/step \n",
            "05/05/2020 07:30:39 - INFO - root -   \n",
            "Epoch: 45 -  loss: 0.0016 - eval_loss: 15.3098 - eval_acc: 0.6319 - eval_recall: 0.5845 - eval_f1: 0.6072 \n",
            "Epoch 46/50\n",
            "[Training] 66/66 [==============================] 195.9ms/step  loss: 0.0001  \n",
            "05/05/2020 07:30:52 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 754.2ms/step \n",
            "05/05/2020 07:30:58 - INFO - root -   \n",
            "Epoch: 46 -  loss: 0.0017 - eval_loss: 15.3208 - eval_acc: 0.6319 - eval_recall: 0.5845 - eval_f1: 0.6072 \n",
            "Epoch 47/50\n",
            "[Training] 66/66 [==============================] 195.2ms/step  loss: 0.0003  \n",
            "05/05/2020 07:31:11 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 756.1ms/step \n",
            "05/05/2020 07:31:18 - INFO - root -   \n",
            "Epoch: 47 -  loss: 0.0028 - eval_loss: 15.2712 - eval_acc: 0.6304 - eval_recall: 0.5898 - eval_f1: 0.6094 \n",
            "\n",
            "Epoch 00047: reducing learning rate to 1.5625e-05.\n",
            "Epoch 48/50\n",
            "[Training] 66/66 [==============================] 196.2ms/step  loss: 0.0001  \n",
            "05/05/2020 07:31:31 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 766.3ms/step \n",
            "05/05/2020 07:31:38 - INFO - root -   \n",
            "Epoch: 48 -  loss: 0.0098 - eval_loss: 15.2707 - eval_acc: 0.6286 - eval_recall: 0.5898 - eval_f1: 0.6086 \n",
            "Epoch 49/50\n",
            "[Training] 66/66 [==============================] 195.7ms/step  loss: 0.0002  \n",
            "05/05/2020 07:31:51 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 755.0ms/step \n",
            "05/05/2020 07:31:58 - INFO - root -   \n",
            "Epoch: 49 -  loss: 0.0016 - eval_loss: 15.2757 - eval_acc: 0.6314 - eval_recall: 0.5925 - eval_f1: 0.6113 \n",
            "Epoch 50/50\n",
            "[Training] 66/66 [==============================] 195.0ms/step  loss: 0.0001  \n",
            "05/05/2020 07:32:11 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 752.1ms/step \n",
            "05/05/2020 07:32:17 - INFO - root -   \n",
            "Epoch: 50 -  loss: 0.0021 - eval_loss: 15.2808 - eval_acc: 0.6286 - eval_recall: 0.5898 - eval_f1: 0.6086 \n",
            "\n",
            "Epoch 00050: reducing learning rate to 7.8125e-06.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fwZFMXQloyIe",
        "colab_type": "code",
        "outputId": "6d09e829-950d-41ea-9135-d820dc077a1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!python run_lstm_crf.py --do_eval"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/05/2020 07:32:22 - INFO - root -   loading model from outputs/bilstm_crf/best-model.bin .\n",
            "05/05/2020 07:32:22 - INFO - root -   Loading features from cached file dataset/cluener/cached_crf-dev_bilstm_crf_ner\n",
            "9 batches created\n",
            "[Evaluating] 9/9 [==============================] 759.0ms/step \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qNvs6gefdfN",
        "colab_type": "code",
        "outputId": "b2cb9ca1-3e4a-44e1-a3a2-2c91b27b512c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!python run_lstm_crf.py --do_predict"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "05/05/2020 07:32:34 - INFO - root -   loading model from outputs/bilstm_crf/best-model.bin .\n",
            "[Training] 10632/10632 [==============================] 34.6ms/step \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50NFgpzYQG9q",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}