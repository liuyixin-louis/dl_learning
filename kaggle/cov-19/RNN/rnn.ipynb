{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37364bitdlcondac3dbe8268fc946eb953798b374dbdaa9",
   "display_name": "Python 3.7.3 64-bit ('dl': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# data prepare"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "../data/test.csv\n../data/train.csv\n../data/submission.csv\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "\n",
    "for dirname, _, filenames in os.walk('../data'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = gpd.read_file(\"./data/train.csv\")\n",
    "train_df[\"ConfirmedCases\"] = train_df[\"ConfirmedCases\"].astype(\"float\")\n",
    "train_df[\"Fatalities\"] = train_df[\"Fatalities\"].astype(\"float\")\n",
    "#The country_region got modified in the enriched dataset by @optimo, \n",
    "# so we have to apply the same change to this Dataframe to facilitate the merge.\n",
    "train_df[\"Country_Region\"] = [ row.Country_Region.replace(\"'\",\"\").strip(\" \") if row.Province_State==\"\" else str(row.Country_Region+\"_\"+row.Province_State).replace(\"'\",\"\").strip(\" \") for idx,row in train_df.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Still using the enriched data from week 2 as there is everything required for the model's training\n",
    "extra_data_df = gpd.read_file(\"/kaggle/input/enriched-covid-19-week2/enriched_covid_19_week_2.csv\")\n",
    "extra_data_df[\"Country_Region\"] = [country_name.replace(\"'\",\"\") for country_name in extra_data_df[\"Country_Region\"]]\n",
    "extra_data_df[\"restrictions\"] = extra_data_df[\"restrictions\"].astype(\"int\")\n",
    "extra_data_df[\"quarantine\"] = extra_data_df[\"quarantine\"].astype(\"int\")\n",
    "extra_data_df[\"schools\"] = extra_data_df[\"schools\"].astype(\"int\")\n",
    "extra_data_df[\"total_pop\"] = extra_data_df[\"total_pop\"].astype(\"float\")\n",
    "extra_data_df[\"density\"] = extra_data_df[\"density\"].astype(\"float\")\n",
    "extra_data_df[\"hospibed\"] = extra_data_df[\"hospibed\"].astype(\"float\")\n",
    "extra_data_df[\"lung\"] = extra_data_df[\"lung\"].astype(\"float\")\n",
    "extra_data_df[\"total_pop\"] = extra_data_df[\"total_pop\"]/max(extra_data_df[\"total_pop\"])\n",
    "extra_data_df[\"density\"] = extra_data_df[\"density\"]/max(extra_data_df[\"density\"])\n",
    "extra_data_df[\"hospibed\"] = extra_data_df[\"hospibed\"]/max(extra_data_df[\"hospibed\"])\n",
    "extra_data_df[\"lung\"] = extra_data_df[\"lung\"]/max(extra_data_df[\"lung\"])\n",
    "extra_data_df[\"age_100+\"] = extra_data_df[\"age_100+\"].astype(\"float\")\n",
    "extra_data_df[\"age_100+\"] = extra_data_df[\"age_100+\"]/max(extra_data_df[\"age_100+\"])\n",
    "\n",
    "extra_data_df = extra_data_df[[\"Country_Region\",\"Date\",\"restrictions\",\"quarantine\",\"schools\",\"hospibed\",\"lung\",\"total_pop\",\"density\",\"age_100+\"]]\n",
    "extra_data_df.head()"
   ]
  }
 ]
}