{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQ9fw27nYU6hwER5XUOD/N",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/liuyixin-louis/dl_learning/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEKADkAPpnA8",
        "colab_type": "text"
      },
      "source": [
        "# CNN KERAS\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj3YrhVqJJ1e",
        "colab_type": "code",
        "outputId": "4196f73c-6688-481d-e959-53f543aadb03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# https://github.com/keras-team/keras/tree/master/examples\n",
        "'''Trains a simple convnet on the MNIST dataset.\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "(there is still a lot of margin for parameter tuning).\n",
        "16 seconds per epoch on a GRID K520 GPU.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 2\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "best_accuracy = 0\n",
        "best_po = 0\n",
        "\n",
        "for i in range(10):\n",
        "  drop_po = (i+1)*1.0/11\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                  activation='relu',\n",
        "                  input_shape=input_shape))\n",
        "  model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  # model.add(Dropout(drop_po))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dropout(drop_po))\n",
        "  model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "  model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "                optimizer=keras.optimizers.Adadelta(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  model.fit(x_train, y_train,\n",
        "            batch_size=batch_size,\n",
        "            epochs=epochs,\n",
        "            verbose=1,\n",
        "            validation_data=(x_test, y_test))\n",
        "\n",
        "  score = model.evaluate(x_test, y_test, verbose=0)\n",
        "  if score[1]> best_accuracy:\n",
        "    best_accuracy = score[1]\n",
        "    best_po = drop_po\n",
        "  \n",
        "  print('Test loss:', score[0])\n",
        "  print('Test accuracy:', score[1])\n",
        "print('best droput possiblity is',best_po)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.2005 - acc: 0.9372 - val_loss: 0.0525 - val_acc: 0.9830\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0487 - acc: 0.9851 - val_loss: 0.0384 - val_acc: 0.9880\n",
            "Test loss: 0.038437227875960524\n",
            "Test accuracy: 0.988\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0570 - acc: 0.9824 - val_loss: 0.0346 - val_acc: 0.9876\n",
            "Test loss: 0.034626256715727506\n",
            "Test accuracy: 0.9876\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 6s 105us/step - loss: 0.2168 - acc: 0.9328 - val_loss: 0.0490 - val_acc: 0.9853\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.0647 - acc: 0.9808 - val_loss: 0.0402 - val_acc: 0.9861\n",
            "Test loss: 0.0401721857199911\n",
            "Test accuracy: 0.9861\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 6s 104us/step - loss: 0.2233 - acc: 0.9315 - val_loss: 0.0581 - val_acc: 0.9808\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.0673 - acc: 0.9796 - val_loss: 0.0463 - val_acc: 0.9847\n",
            "Test loss: 0.04632888280235347\n",
            "Test accuracy: 0.9847\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 6s 106us/step - loss: 0.2655 - acc: 0.9189 - val_loss: 0.0506 - val_acc: 0.9824\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 81us/step - loss: 0.0785 - acc: 0.9769 - val_loss: 0.0380 - val_acc: 0.9872\n",
            "Test loss: 0.03803506151833572\n",
            "Test accuracy: 0.9872\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 6s 108us/step - loss: 0.2821 - acc: 0.9134 - val_loss: 0.0625 - val_acc: 0.9803\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.0956 - acc: 0.9719 - val_loss: 0.0469 - val_acc: 0.9844\n",
            "Test loss: 0.04693643154799938\n",
            "Test accuracy: 0.9844\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 7s 115us/step - loss: 0.3135 - acc: 0.9030 - val_loss: 0.0784 - val_acc: 0.9747\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 84us/step - loss: 0.1126 - acc: 0.9681 - val_loss: 0.0417 - val_acc: 0.9861\n",
            "Test loss: 0.041689236143929886\n",
            "Test accuracy: 0.9861\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.3785 - acc: 0.8828 - val_loss: 0.0685 - val_acc: 0.9787\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.1424 - acc: 0.9585 - val_loss: 0.0451 - val_acc: 0.9853\n",
            "Test loss: 0.045093776158220134\n",
            "Test accuracy: 0.9853\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 7s 113us/step - loss: 0.5077 - acc: 0.8366 - val_loss: 0.0757 - val_acc: 0.9762\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 82us/step - loss: 0.2207 - acc: 0.9328 - val_loss: 0.0550 - val_acc: 0.9826\n",
            "Test loss: 0.05500283660684945\n",
            "Test accuracy: 0.9826\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/2\n",
            "60000/60000 [==============================] - 7s 112us/step - loss: 0.9642 - acc: 0.6477 - val_loss: 0.1272 - val_acc: 0.9671\n",
            "Epoch 2/2\n",
            "60000/60000 [==============================] - 5s 83us/step - loss: 0.5769 - acc: 0.7822 - val_loss: 0.0813 - val_acc: 0.9753\n",
            "Test loss: 0.08125260707307606\n",
            "Test accuracy: 0.9753\n",
            "best droput possiblity is 0.09090909090909091\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8e979xxFB_i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "81683a8d-99ff-4946-922e-1f22665ab939"
      },
      "source": [
        "y_test"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    }
  ]
}